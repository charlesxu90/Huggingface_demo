{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2e857ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --ignore-installed PyYAML\n",
    "#!pip install transformers\n",
    "#!pip install tensorflow\n",
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0708135-84f0-4724-b4f7-db6f97cf5b89",
   "metadata": {},
   "source": [
    "# Train a model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b97edbc-7c94-413e-bfba-b07c6d69638c",
   "metadata": {},
   "source": [
    "## Train Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15a254cc-1380-43e2-a475-3438c5315276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this notebook we'll only get one of the files (the Oscar one) for the sake of simplicity and performance\n",
    "#!wget -c https://cdn-datasets.huggingface.co/EsperBERTo/data/oscar.eo.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dd3ba41-6c41-4882-a69b-3a7a511d66e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 55s, sys: 2min 36s, total: 18min 32s\n",
      "Wall time: 41.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from pathlib import Path\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "paths = [str(x) for x in Path(\".\").glob(\"**/*.txt\")]\n",
    "\n",
    "# Initialize a tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "# Customize training\n",
    "tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2, special_tokens=[\n",
    "    \"<s>\",\n",
    "    \"<pad>\",\n",
    "    \"</s>\",\n",
    "    \"<unk>\",\n",
    "    \"<mask>\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f220d4a-462b-4812-b23d-6c8722ec383b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory â€˜EsperBERToâ€™: File exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['EsperBERTo/vocab.json', 'EsperBERTo/merges.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!mkdir EsperBERTo\n",
    "tokenizer.save_model(\"EsperBERTo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f6d62b-7c5c-4f30-a2d3-c919fd96bb81",
   "metadata": {},
   "source": [
    "### Use Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cbd348f-93f5-4110-9c4c-aa37427ea821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./EsperBERTo/vocab.json\",\n",
    "    \"./EsperBERTo/merges.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c551cac4-82e3-45a0-84e6-cb9de597b441",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")\n",
    "tokenizer.enable_truncation(max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c80ebbbe-bb64-45a6-80bd-f967749e8672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=7, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Mi estas Julien.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b30a7807-81b4-4a84-b9dd-629034f69959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'Mi', 'Ä estas', 'Ä Juli', 'en', '.', '</s>']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Mi estas Julien.\").tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649387ef-466d-4052-92e8-5fca3c8acc88",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8913fc2a-0048-42ae-b48b-6514d7b931fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that PyTorch sees it\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6712e64b-f4b2-4055-963b-dfcab2303796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=52_000,\n",
    "    max_position_embeddings=514,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c83d2816-bec9-45bf-ad86-82f18a067d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Sep  9 11:07:54 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro M2000        Off  | 00000000:AF:00.0  On |                  N/A |\n",
      "| 56%   43C    P0    23W /  75W |    798MiB /  4040MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2329      G   /usr/lib/xorg/Xorg                404MiB |\n",
      "|    0   N/A  N/A      2720      G   ..._26867.log --shared-files       60MiB |\n",
      "|    0   N/A  N/A      4205      G   /usr/bin/gnome-shell              105MiB |\n",
      "|    0   N/A  N/A     37933      G   ...AAAAAAAAA= --shared-files      216MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9158f01f-b4c2-4d40-88ef-aed17e9107e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"./EsperBERTo\", max_len=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d360683-e462-4647-b6b8-0902266130c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM\n",
    "\n",
    "model = RobertaForMaskedLM(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "862d087f-dcc2-4588-aa2d-c825bfa822d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83504416"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()\n",
    "# => 84 million parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da62d1e7-a738-4e15-885e-675e5f0cce5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaopengxu/anaconda3/envs/ml-env/lib/python3.8/site-packages/transformers/data/datasets/language_modeling.py:120: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29min 20s, sys: 37.9 s, total: 29min 58s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import LineByLineTextDataset\n",
    "\n",
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"./oscar.eo.txt\",\n",
    "    block_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0eb0f9ec-bc89-48ce-814f-0e6c5de42876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b02e261-1463-486c-8d0a-eb8dfa3e0164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./EsperBERTo\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_gpu_train_batch_size=64,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eef4081-f057-484c-beee-002eff62aa5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd395a88-b259-410b-9034-eb825b6f41ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6c5d60-cdd0-47a3-8ee7-cfd7f7763cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./EsperBERTo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f817e17-a6ab-49ee-9fe0-9dfecedc2a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_mask = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=\"./EsperBERTo\",\n",
    "    tokenizer=\"./EsperBERTo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a7c95a-8f2a-4ab1-8cc3-2bb1bf567c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sun <mask>.\n",
    "# =>\n",
    "\n",
    "fill_mask(\"La suno <mask>.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f813ec-e7c3-43aa-85ee-e1422020366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_mask(\"Jen la komenco de bela <mask>.\")\n",
    "\n",
    "# This is the beginning of a beautiful <mask>.\n",
    "# =>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
